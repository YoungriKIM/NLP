{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 출처: https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv\n",
    "# 챗봇 트레이닝용 문답 페어 11,876개\n",
    "# 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2로 레이블링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "from datetime import datetime\n",
    "import random\n",
    "device = torch.device(\"cuda:1\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델, 토크나이저 불러오기\n",
    "from transformers import DistilBertModel\n",
    "distilbert_model = DistilBertModel.from_pretrained('monologg/distilkobert')\n",
    "dimodel = distilbert_model.to(device)\n",
    "\n",
    "from tokenization_kobert import KoBertTokenizer\n",
    "tokenizer = KoBertTokenizer.from_pretrained('monologg/distilkobert')\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "print(len(vocab))\n",
    "print(tokenizer.tokenize(\"[CLS] 한국어 모델을 공유합니다. [SEP]\"))\n",
    "tokenizer.convert_tokens_to_ids(['[CLS]', '▁한국', '어', '▁모델', '을', '▁공유', '합니다', '.', '[SEP]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPOCESSING\n",
    "class diBERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, tokenizer, max_len):\n",
    "        def ditransform(sent):\n",
    "            sent_tok = [2] + tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent)) + [3]\n",
    "            token_ids = sent_tok + [1]*(max_len - len(sent_tok))\n",
    "            return np.array(token_ids, dtype='int32'), np.array(len(sent_tok), dtype='int32')\n",
    "\n",
    "        self.sentences = [ditransform(i[sent_idx]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, verbose=False, delta=0, path ='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_acc_max = -np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_acc, model):\n",
    "\n",
    "        score = val_acc\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_acc, model)\n",
    "        elif score <= self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_acc, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_acc, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation acc decreased ({self.val_acc_max:.6f} --> {val_acc:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path) # 싱글 GPU\n",
    "        # torch.save(model.module.state_dict(), self.path) # 멀티 GPU\n",
    "\n",
    "        self.val_acc_max = val_acc"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
